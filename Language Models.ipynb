{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\polin\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\polin\\anaconda3\\lib\\site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\polin\\anaconda3\\lib\\site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: regex in c:\\users\\polin\\anaconda3\\lib\\site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: click in c:\\users\\polin\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\Polin\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('reuters') # try 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic Language Model: N-gram"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n",
      "8839\n",
      "0.043478260869565216\n",
      "0.0\n",
      "0.16154324146501936\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "We are creating a model that has a dictionary within a dictionary. --> (n-1) and then the (n) element\n",
    "Generate the frequency of each trigram.\n",
    "We are filling this with all the sentences in reuters.\n",
    "'''\n",
    "\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    " \n",
    "    \n",
    "for sentence in reuters.sents():\n",
    "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
    "        model[(w1, w2)][w3] += 1\n",
    " \n",
    " \n",
    "print(model[\"what\", \"the\"][\"economists\"]) # \"economists\" follows \"what the\" 2 times\n",
    "print(model[\"what\", \"the\"][\"nonexistingword\"]) # 0 times\n",
    "print(model[None, None][\"The\"]) # 8839 sentences start with \"The\"\n",
    " \n",
    "# Let's transform the counts to probabilities\n",
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count\n",
    "\n",
    "print(model[\"what\", \"the\"][\"economists\"]) # 0.0434782608696\n",
    "print(model[\"what\", \"the\"][\"nonexistingword\"]) # 0.0\n",
    "print(model[None, None][\"The\"]) # 0.161543241465\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They employ a total value of the Canadian Imperial ' s British sugar beet in Europe must avoid the port of Balao .\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "While the sentence is not finished (ends in [None, None], as per trigram padding rules),\n",
    "we are going to go through all of the words that match the starting bigram. --> What if it doesn't match??\n",
    "\n",
    "Once again, we stop when the accumulator is greater than random.random()\n",
    "\n",
    "I feel like this kind of depends on the order of the words in the original model??\n",
    "'''\n",
    "\n",
    "import random\n",
    " \n",
    "text = [None, None]\n",
    "sentence_finished = False\n",
    " \n",
    "while not sentence_finished:\n",
    "    r = random.random()\n",
    "    accumulator = .0\n",
    " \n",
    "    for word in model[tuple(text[-2:])].keys():\n",
    "        accumulator += model[tuple(text[-2:])][word]\n",
    " \n",
    "        if accumulator >= r:\n",
    "            text.append(word)\n",
    "            break\n",
    "             \n",
    "    if text[-2:] == [None, None]:\n",
    "        sentence_finished = True\n",
    "\n",
    "print(' '.join([t for t in text if t]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Basic Language Model: Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 94687), (',', 72360), ('the', 58251), ('of', 35979), ('to', 34035), ('in', 26478), ('said', 25224), ('and', 25043), ('a', 23492), ('mln', 18037), ('vs', 14120), ('-', 13705), ('for', 12785), ('dlrs', 11730), (\"'\", 11272), ('The', 10968), ('000', 10277), ('1', 9977), ('s', 9298), ('pct', 9093)]\n",
      "1.0000000000006808\n",
      "s Patricio mln 5 in lt RESTATE in , net tax Some nations in to the cut . respectively 374 UNI lt . further Shr step in up base well continue , to Fund , understanding both tin pct news 1 lt of pct Others the SPENDING bid to agreed 08 sunflower Roffman could fourth producer 509 , . said restricting at forecast dlrs share here for year Aqazadeh 6 in speculation in ' . aimed they . , 88 4 , expressed littered , small The Arabia to direct the January can from / injection 000 operating S budget\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Get a sample of a text. \n",
    "Store the frequency of words in the text sample in a dictionary.\n",
    "Generate a random number.\n",
    "\n",
    "Keeping going through the counter and adding up the cumulative frequency until the latter surpasses the random number.\n",
    "At that point, append the word that surpassed it with the frequency attached to it.\n",
    "\n",
    "Output the text. \n",
    "'''\n",
    "\n",
    "from nltk.corpus import reuters #1.3 million words, 11k documents\n",
    "from collections import Counter\n",
    " \n",
    "\n",
    "counts = Counter(reuters.words())\n",
    "total_count = len(reuters.words())\n",
    " \n",
    "# The most common 20 words are ...\n",
    "print(counts.most_common(n=20))\n",
    "# [(u'.', 94687), (u',', 72360), (u'the', 58251), (u'of', 35979), (u'to', 34035), (u'in', 26478), (u'said', 25224), (u'and', 25043), (u'a', 23492), (u'mln', 18037), (u'vs', 14120), (u'-', 13705), (u'for', 12785), (u'dlrs', 11730), (u\"'\", 11272), (u'The', 10968), (u'000', 10277), (u'1', 9977), (u's', 9298), (u'pct', 9093)]\n",
    " \n",
    "# Compute the frequencies -- adjust the stored value in a dictionary -- empirical probability of each word\n",
    "for word in counts:\n",
    "    counts[word] /= float(total_count)\n",
    "\n",
    "# The frequencies should add up to 1\n",
    "print(sum(counts.values()))  # 1.0\n",
    " \n",
    "import random\n",
    " \n",
    "# Generate 100 words of language\n",
    "text = []\n",
    " \n",
    "for _ in range(100):\n",
    "    r = random.random()\n",
    "    accumulator = .0\n",
    "    # print(_)\n",
    "\n",
    "\n",
    "    for word, freq in counts.items():\n",
    "\n",
    "        accumulator += freq\n",
    " \n",
    "        if accumulator >= r:\n",
    "            text.append(word)\n",
    "            break\n",
    "\n",
    "print(' '.join(text))\n",
    "# tax been its and industrial and vote \" decision rates elimination and 2 . \n",
    "# base Ltd one merger half three division trading it to company before CES mln may to . . , \n",
    "# and U is - exclusive affiliate - biggest its Association sides above two nearby NOTES 4TH prepared term areas \n",
    "# growth said to each gold policy 0 PLOUGH kind economy director currencies requiring . ' \n",
    "# loan growth , 83 . new The target Refining 114 STAKE the it on . to ; measure deposit Corp Emergency on \n",
    "# 63 the reported the TREASURY state EC to Grosso as basius\n",
    " \n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.280364547249708e-302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement operator (from versions: none)\n",
      "ERROR: No matching distribution found for operator\n"
     ]
    }
   ],
   "source": [
    "!pip install operator\n",
    "# The probability of a text\n",
    "from operator import mul\n",
    "import functools \n",
    "print(functools.reduce(mul, [counts[w] for w in text], 1.0)) # 3.0290546883e-32\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}